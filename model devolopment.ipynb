{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler  # Handle class imbalance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('ecommerce_data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Get dataset summary\n",
    "print(data.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Fill or drop missing values\n",
    "data.fillna('', inplace=True)\n",
    "\n",
    "# Example for text data preprocessing\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Assuming 'product' column is the text column you want to clean\n",
    "data['cleaned_text'] = data['product'].apply(clean_text)\n",
    "\n",
    "# Convert categorical data to numerical\n",
    "categorical_columns = ['user id', 'product id']\n",
    "data = pd.get_dummies(data, columns=categorical_columns)\n",
    "\n",
    "# Convert 'rating' to binary target\n",
    "data['binary_rating'] = (data['rating'] >= 1000).astype(int)\n",
    "\n",
    "# Check class distribution\n",
    "print(data['binary_rating'].value_counts())\n",
    "\n",
    "X = data.drop(['rating', 'product', 'cleaned_text', 'binary_rating'], axis=1)\n",
    "y = data['binary_rating']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance using RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(pd.Series(y_train_bal).value_counts())\n",
    "\n",
    "# Dummy variables\n",
    "vocab_size = 5000\n",
    "embedding_dim = 128\n",
    "max_length = 100\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(128),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_bal, y_train_bal, epochs=50, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Adjust the threshold\n",
    "threshold = 0.5  # Start with default, then adjust if needed\n",
    "predictions = (predictions > threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Generate and plot the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('confusion_matrix.png')  # Saving the plot with a specified name\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "model.save('product_recommendation_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
